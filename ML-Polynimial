import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_log_error, r2_score

# Load the dataset
data = pd.read_csv('/content/sample_data/california_housing_test.csv')
# Select an independent variable and the dependent variable
X = data.loc[0:5, ["housing_median_age"]]
y = data.loc[0:5, "latitude"]

# Create a polynomial regression model
degree = 2  # Choose the degree of the polynomial (e.g., 2 for quadratic)
poly = PolynomialFeatures(degree=degree)
X_poly = poly.fit_transform(X)

model = LinearRegression()

# Fit the model to the polynomial features
model.fit(X_poly, y)

# Predict using the trained model
y_pred = model.predict(X_poly)

# Calculate Mean Squared Logarithmic Error (MSLE) and R-squared
mse = mean_squared_log_error(y, y_pred)
r_squared = r2_score(y, y_pred)

print("Mean Squared Logarithmic Error (MSLE):", mse)
print("R-squared (Coefficient of Determination):", r_squared)

# Print model coefficients
print("Intercept (b0):", model.intercept_)
print("Coefficients (b1, b2, ...):", model.coef_)

# Create a scatter plot of actual vs. predicted values
plt.scatter(X, y, color='blue', label='Actual')
plt.scatter(X, y_pred, color='red', label='Predicted')
plt.xlabel("Housing Median Age")
plt.ylabel("Latitude")
plt.title("Polynomial Regression")
plt.legend()
plt.show()
